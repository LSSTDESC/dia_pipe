import numpy as np

import lsst.afw.table as afwTable
import lsst.pex.config as pexConfig
import lsst.daf.base as dafBase
import lsst.pipe.base as pipeBase
import lsst.pex.config as pexconfig
import lsst.geom as geom

from lsst.meas.base.noiseReplacer import NoiseReplacer
from lsst.meas.base.references import MultiBandReferencesTask, BaseReferencesTask, CoaddSrcReferencesTask
from lsst.meas.base.forcedPhotCcd import ForcedPhotCcdTask, ForcedPhotCcdConfig, PerTractCcdDataIdContainer
from lsst.meas.base.forcedMeasurement import ForcedPluginConfig, ForcedPlugin
from lsst.meas.base.pluginRegistry import register


__all__ = ("ForcedPhotCcdDiaConfig", "ForcedPhotCcdDiaTask")


class DiaReferencesConfig(CoaddSrcReferencesTask.ConfigClass):

	def validate(self):
		if self.filter is not None:
			raise pexConfig.FieldValidationError(
				field=MultiBandReferencesConfig.filter,
				config=self,
				msg="Filter should not be set for the multiband processing scheme")
		# Delegate to ultimate base class, because the direct one has a check we don't want.
		BaseReferencesTask.ConfigClass.validate(self)

	def setDefaults(self):
		self.skipMissing = True


class DiaReferencesTask(CoaddSrcReferencesTask):
	"""!
	Loads references from the multiband processing scheme.  

	This is different from the standard CoaddSrcReferenceTask in that we construct a whole catalog
	and not a generator.  Some downstream parts of the code currently expect to be able to
	find the length.
	"""
	ConfigClass = DiaReferencesConfig
	datasetSuffix = "diaObject"

	#def __init__(self, butler=None, schema=None, **kwargs):
	#	"""!Initialize the task.
	#	BaseReferencesTask and its subclasses take two keyword arguments beyond the usual Task arguments:
	#	 - schema: the Schema of the reference catalog
	#	 - butler: a butler that will allow the task to load its Schema from disk.
	#	At least one of these arguments must be present; if both are, schema takes precedence.
	#	"""
	#	CoaddSrcReferencesTask.__init__(self, butler=butler, schema=schema, **kwargs)
	#	print('Creating new referencetask')
	#	self.catalog_cache = {}

	def fetchInBox(self, dataRef, bbox, wcs, pad=0):
		"""!
		Return reference sources that overlap a region defined by a pixel-coordinate bounding box
		and corresponding Wcs.
		@param[in] dataRef    ButlerDataRef; the implied data ID must contain the 'tract' key.
		@param[in] bbox       a geom.Box2I or Box2D that defines the region in pixel coordinates
		@param[in] wcs        afw.image.Wcs that maps the bbox to sky coordinates
		@param[in] pad        a buffer to grow the bounding box by after catalogs have been loaded, but
							  before filtering them to include just the given bounding box.
		@return an iterable of reference sources
		"""
		skyMap = dataRef.get(self.config.coaddName + "Coadd_skyMap", immediate=True)
		tract = skyMap[int(dataRef.dataId["tract"])]
		coordList = [wcs.pixelToSky(corner) for corner in geom.Box2D(bbox).getCorners()]
		self.log.info("Getting references in region with corners %s [degrees]" %
					  ", ".join("(%s)" % (coord.getPosition(geom.degrees),) for coord in coordList))
		patchList = tract.findPatchList(coordList)
		# After figuring out which patch catalogs to read from the bbox, pad out the bbox if desired
		# But don't add any new patches while padding
		if pad:
			bbox.grow(pad)
		catalog = self.fetchInPatches(dataRef, patchList)

		if catalog is not None:
			return self.subset(catalog, bbox, wcs)
		else:
			return None
			

	def fetchInPatches(self, dataRef, patchList):
		"""!
		An implementation of BaseReferencesTask.fetchInPatches that loads 'coadd_' + datasetSuffix
		catalogs using the butler.
		
		The given dataRef must include the tract in its dataId.
		"""
		dataset = "{}Coadd_{}".format(self.config.coaddName, self.datasetSuffix)
		tract = dataRef.dataId["tract"]
		butler = dataRef.butlerSubset.butler
		catalog = None

		#skyMap = dataRef.get(self.config.coaddName + "Coadd_skyMap", immediate=True)
		#refWcs = skyMap[int(dataRef.dataId["tract"])].getWcs()
		refWcs = self.getWcs(dataRef)
		for patch in patchList:
			#label = "%d_" % tract +  "%d,%d" % patch.getIndex()
			#if label in self.catalog_cache.keys():
			#	new_catalog = self.catalog_cache[label]
			#	print('Found cache')
			#else:
			dataId = {'tract': tract, 'patch': "%d,%d" % patch.getIndex()}
			if self.config.filter is not None:
				dataId['filter'] = self.config.filter
	
			if not butler.datasetExists(dataset, dataId):
				if self.config.skipMissing:
					continue
				raise pipeBase.TaskError("Reference %s doesn't exist" % (dataId,))
			self.log.info("Getting references in %s" % (dataId,))
				
			new_catalog = butler.get(dataset, dataId, immediate=True)
			#self.catalog_cache[label] = new_catalog

			bbox = geom.Box2D(patch.getInnerBBox())

			
			if self.config.removePatchOverlaps:
				valid = np.array([bbox.contains(refWcs.skyToPixel(s.getCoord())) for s in new_catalog])
			else:
				valid = np.array([True]*len(new_catalog))
			
			if catalog is None:
				catalog = new_catalog[valid]
			else:
				catalog.extend(new_catalog[valid])	

		return catalog
	def subset(self, sources, bbox, wcs):
		"""Filter on sources that are in the given bbox
		"""
		if sources is None:
			return sources
		boxD = geom.Box2D(bbox)

		skyCoordList = [source.getCoord() for source in sources]
		pixelPosList = wcs.skyToPixel(skyCoordList)
		mask = np.array([boxD.contains(pixel) for pixel in pixelPosList])
		return sources[mask]


class ForcedDiaTransformedCentroidConfig(ForcedPluginConfig):
	pass


@register("base_DiaTransformedCentroid")
class ForcedDiaTransformedCentroidPlugin(ForcedPlugin):
	"""A centroid pseudo-algorithm for forced measurement that simply transforms sky coordinate
	from the reference catalog to the measurement coordinate system.  This does assumes that
	there is no centroid column in the refernce catalog.
	"""

	ConfigClass = ForcedDiaTransformedCentroidConfig

	@classmethod
	def getExecutionOrder(cls):
		return cls.CENTROID_ORDER

	def __init__(self, config, name, schemaMapper, metadata):
		ForcedPlugin.__init__(self, config, name, schemaMapper, metadata)
		schema = schemaMapper.editOutputSchema()
		# Allocate x and y fields, join these into a single FunctorKey for ease-of-use.
		xKey = schema.addField(name + "_x", type="D", doc="transformed reference centroid column",
							   units="pixel")
		yKey = schema.addField(name + "_y", type="D", doc="transformed reference centroid row",
							   units="pixel")
		self.centroidKey = afwTable.Point2DKey(xKey, yKey)

	def measure(self, measRecord, exposure, refRecord, refWcs):
		targetWcs = exposure.getWcs()
		targetPos = targetWcs.skyToPixel(refRecord.getCoord())
		measRecord.set(self.centroidKey, targetPos)
		


class ForcedPhotCcdDiaConfig(ForcedPhotCcdConfig):

	def setDefaults(self):
		ForcedPhotCcdTask.ConfigClass.setDefaults(self)
		self.references.retarget(DiaReferencesTask)
		self.measurement.copyColumns = {"id": "dia_object_id", "coord_ra": "coord_ra", "coord_dec": "coord_dec"}
		self.measurement.plugins.names = ['base_GaussianFlux', 'base_SdssShape', 'base_DiaTransformedCentroid', 
										  'base_PsfFlux', 'base_CircularApertureFlux', 'base_LocalBackground', 
										  'base_PixelFlags', 'base_SdssCentroid']
		self.measurement.slots.centroid = 'base_DiaTransformedCentroid'
		self.measurement.slots.shape = 'base_SdssShape'
		self.measurement.slots.apFlux = 'base_CircularApertureFlux_3_0'
		self.measurement.slots.modelFlux = 'base_PsfFlux'
		self.measurement.slots.psfFlux = 'base_PsfFlux'
		self.measurement.slots.instFlux = 'base_PsfFlux'
		self.measurement.slots.calibFlux = 'base_PsfFlux'


class ForcedPhotCcdDiaTask(ForcedPhotCcdTask):
	"""!
	A command-line driver for performing forced measurement on CCD images from DIA catalogs.

	This task is a subclass of ForcedPhotCcdTask.  This overides things that were not working
	for the ForcedPhotCcdTask and extends them to use the DIA inputs.
	"""

	ConfigClass = ForcedPhotCcdDiaConfig
	RunnerClass = pipeBase.ButlerInitializedTaskRunner
	_DefaultName = "forcedPhotCcdDia"
	dataPrefix = ""

	def writeOutput(self, dataRef, sources):
		"""!Write forced source table
		@param dataRef  Data reference from butler; the forced_src dataset (with self.dataPrefix included)
						is all that will be modified.
		@param sources  SourceCatalog to save
		"""
		dataRef.put(sources, self.dataPrefix + "deepCoadd_forced_dia_src", flags=afwTable.SOURCE_IO_NO_FOOTPRINTS)


	def _getConfigName(self):
		"""!Return the name of the config dataset.  Forces config comparison from run-to-run
		"""
		return self.dataPrefix + "forcedPhotCcdDia_config"
	
	def _getMetadataName(self):
		"""!Return the name of the metadata dataset.  Forced metadata to be saved
		"""
		return self.dataPrefix + "forcedPhotCcdDia_metadata"

	@classmethod
	def _makeArgumentParser(cls):
		parser = pipeBase.ArgumentParser(name=cls._DefaultName)
		parser.add_id_argument("--id", "deepCoadd_forced_dia_src", help="data ID with raw CCD keys [+ tract optionally], "
							   "e.g. --id visit=12345 ccd=1,2 [tract=0]",
							   ContainerClass=PerTractCcdDataIdContainer)
		return parser

	def fetchReferences(self, dataRef, exposure):
		"""Return a SourceCatalog of sources which overlap the exposure.

		We assume that all objects are isolated.  We do not filter out bad footprints or sort
		them as is done in ForcedPhotCcdTask.

		@param dataRef       Data reference from butler corresponding to the image to be measured;
							 should have tract, patch, and filter keys.
		@param exposure      lsst.afw.image.Exposure to be measured (used only to obtain a Wcs and
							 bounding box).
		All work is delegated to the references subtask; see CoaddSrcReferencesTask for information
		about the default behavior.
		"""
		references = afwTable.SourceCatalog(self.references.schema)
		unfiltered = self.references.fetchInBox(dataRef, exposure.getBBox(), exposure.getWcs())
		return unfiltered
	

	def run(self, dataRef, psfCache=None):
		"""!Measure a single exposure using forced detection for a reference catalog.
		@param[in]  dataRef   An lsst.daf.persistence.ButlerDataRef. It is passed to the
							  references subtask to obtain the reference WCS, the getExposure()
							  method (implemented by derived classes) to read the measurement
							  image, and the fetchReferences() method (implemented by derived
							  classes) to get the exposure and load the reference catalog (see
							  the CoaddSrcReferencesTask for more information).  Sources are
							  generated with generateMeasCat() in the measurement subtask.  These
							  are passed to measurement's run method which fills the source
							  catalog with the forced measurement results.  The sources are then
							  passed to the writeOutputs() method (implemented by derived classes)
							  which writes the outputs.  See derived class documentation for which
							  datasets and data ID keys are used.
		@param[in]  psfCache  Size of PSF cache, or None. The size of the PSF cache can have
							  a significant effect upon the runtime for complicated PSF models.
		"""
		#dataRef.dataId['tract'] = int(dataRef.dataId['tract'])

		refWcs = self.references.getWcs(dataRef)
		exposure = self.getExposure(dataRef)
		if psfCache is not None:
			exposure.getPsf().setCacheSize(psfCache)
		refCat = self.fetchReferences(dataRef, exposure)
		if refCat is None:
			self.log.warn('Failed to get references for %s. skipping' % dataRef.dataId)
			return
		measCat = self.measurement.generateMeasCat(exposure, refCat, refWcs,
												   idFactory=self.makeIdFactory(dataRef))
		measCat=measCat[:100]

		self.log.info("Performing forced measurement on %s" % (dataRef.dataId,))
		self.attachFootprints(measCat, refCat, exposure, refWcs, dataRef)

		self.measurement.run(measCat, exposure, refCat, refWcs, exposureId=self.getExposureId(dataRef))

		if self.config.doApCorr:
			self.applyApCorr.run(
				catalog=measCat,
				apCorrMap=exposure.getInfo().getApCorrMap()
			)
		self.catalogCalculation.run(measCat)

		self.writeOutput(dataRef, measCat)

